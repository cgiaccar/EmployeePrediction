# -*- coding: utf-8 -*-
"""Previsione_retention_impiegati_svil.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zvgfq1tvVL948ELeOdUEC-ZHCysFMjBK

#Previsione retention impiegati - sviluppo

*UNITS -
224MI PROGETTAZIONE DEL SOFTWARE E DEI SISTEMI INFORMATIVI*

*Versione 27/12/2022-01*

#Estrazione informazioni dal dataset

Il dataset utilizzato si puÃ² scaricare dal sito: https://www.kaggle.com/datasets/tejashvi14/employee-future-prediction

Elenco delle features

1.   Education : The highest level of formal education obtained by the employee
2.   JoiningYear : Year of joining the company
3.   City : Job Location
4.   PaymentTier : [1:3] -> 1 means better payment
5.   Age : Age of the employee
6.   Gender : Gender of the employee
7.   EverBenched : Ever kept out of project for more than one month
8.   ExperienceInCurrentDomain : Experience in current field

Classificazione
9.   LeaveOrNot : Whether the employee leaves the company in next 2 years
"""
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import datetime


def stampa_ora():
    now = datetime.datetime.now()
    print("Current date and time : ")
    print(now.strftime("%Y-%m-%d %H:%M:%S"))


print("*** INIZIO ELABORAZIONE ***")
stampa_ora()

nomeFile = 'Employee.csv'
print('Lettura file dati :' + os.path.dirname(__file__) + '\\' + nomeFile)
fileUtenti = os.path.dirname(__file__) + "/csv/utenti.csv"

df = pd.read_csv('Employee.csv')
df_targets = pd.DataFrame(df, columns=['LeaveOrNot'])
df.head()

print("""Sintesi dei dati ed elenco valori delle classi target""")

print(df.describe().T)
print('\nValori unici delle classi target')
print(df_targets['LeaveOrNot'].unique())

"""## Fase di pre processing

### Gestione valori null

Il data set non ha valori null
"""

df.isnull().sum()

print('> ### Trasformazione dati')
"""> ### Trasformazione dati

Cambio il tipo da stringa a numerico e inverto la classificazione dello stipendio
"""

print(df['Education'].unique())
print(df['Gender'].unique())
print(df['EverBenched'].unique())
print(df['City'].unique())
dfv = df.copy()
dfv['PaymentTier'].replace([1, 2, 3], [3, 2, 1], inplace=True)
dfv['Education'].replace(['Bachelors', 'Masters', 'PHD'], [1, 2, 3], inplace=True)
dfv['Gender'].replace(['Male', 'Female'], [0, 1], inplace=True)
dfv['EverBenched'].replace(['No', 'Yes'], [0, 1], inplace=True)
dfv['City'].replace(['Bangalore', 'New Delhi', 'Pune'], [1, 2, 3], inplace=True)
print(df.head())
dfv.head()
print(dfv.describe().T)

"""# Visualizzazione ed analisi dei dati"""

dfv.hist(bins=8, figsize=(10, 10))
# plt.show(block=False)

plt.figure(figsize=(12, 12))
sns.heatmap(dfv.corr(), annot=True, cbar=False)
# plt.show(block=False)

"""# Sviluppo modello random forest

##Preparazione data set training e test
"""

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

import warnings

warnings.filterwarnings('ignore')

sns.set_theme(style="ticks")

xtrain, xtest, ytrain, ytest = train_test_split(dfv.iloc[:, :-1].values, df_targets.values, test_size=0.3,
                                                random_state=1)
# xtrain.shape, xtest.shape, xtrain.describe().T, xtest.describe().T

"""##Normalizzazione dati"""

norm = MinMaxScaler()

# print(xtrain.iloc[0])
xtrain_norm = norm.fit_transform(xtrain)
print('\nxtrain_norm[0]')
print(xtrain_norm[0])

# print(xtest.iloc[0])
xtest_norm = norm.transform(xtest)
print('\nxtest_norm[0]')
print(xtest_norm[0])

"""##Training del modello"""

# from sklearn.model_selection import GridSearchCV
# from sklearn.ensemble import RandomForestClassifier
#
# model_rfc = RandomForestClassifier(n_jobs=-1)
# parameters = {'n_estimators': [50, 100, 200, 300, 400], 'max_depth': [3, 4, 5, 6]}
# # model_rfc_grid = GridSearchCV(model_rfc, parameters, cv=10, verbose=1, n_jobs=-1).fit(xtrain, ytrain)
# model_rfc_grid = GridSearchCV(model_rfc, parameters, cv=10, verbose=1, n_jobs=-1).fit(xtrain, np.ravel(ytrain))
# print(model_rfc_grid.best_params_)
#
# print('Random Forest Classifier Cros validation score:', model_rfc_grid.best_score_ * 100)

# import sklearn
#
# #sklearn.metrics.plot_confusion_matrix(model_rfc_grid, xtest, ytest)
# #plt.show(block=False)
#
# print(f'{model_rfc_grid} : ')
# print('\nTraining Accuracy : ', sklearn.metrics.f1_score(ytrain, model_rfc_grid.predict(xtrain), average='macro'))
# print('\nValidation Accuracy : ', sklearn.metrics.f1_score(ytest, model_rfc_grid.predict(xtest), average='macro'))
# print('\n ** metrics.classification_report ** \n')
# print(sklearn.metrics.classification_report(ytest, model_rfc_grid.predict(xtest)))

print("""#Sviluppo modello XGboost""")

from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

model_xgb = XGBClassifier(n_jobs=-1, random_state=42, eval_metric='logloss')
parameters = {'n_estimators': [50, 100, 200], 'max_depth': [5, 6], 'learning_rate': [0.1, 0.01]}
model_xgb_grid = GridSearchCV(model_xgb, parameters, cv=10, verbose=1).fit(xtrain, ytrain)
print(model_xgb_grid.best_params_)

print('XGB Classifier Cros validation score:', model_xgb_grid.best_score_ * 100)

model_xgb = XGBClassifier(n_jobs=-1, random_state=42, n_estimators=50, max_depth=5, learning_rate=0.1,
                          eval_metric='logloss')
model_xgb.fit(xtrain, ytrain)
print('XGB Classifier Classifier Train score:', model_xgb.score(xtrain, ytrain) * 100)

"""## Confusion matrix"""

from sklearn import metrics

# metrics.plot_confusion_matrix(model_rfc_grid, xtest, ytest)
# metrics.plot_confusion_matrix(model_xgb, xtest, ytest)
plt.show(block=False)

print("""## Risultati accuratezza""")

# print(f'{model_rfc_grid} : ')
# print('\nTraining Accuracy : ', metrics.f1_score(ytrain, model_rfc_grid.predict(xtrain), average='macro'))
# print('\nValidation Accuracy : ', metrics.f1_score(ytest, model_rfc_grid.predict(xtest), average='macro'))
# print('\n ** metrics.classification_report ** \n')
# print(metrics.classification_report(ytest, model_rfc_grid.predict(xtest)))

print(f'{model_xgb} : ')
print('\nTraining Accuracy : ', metrics.f1_score(ytrain, model_xgb.predict(xtrain), average='macro'))
print('\nValidation Accuracy : ', metrics.f1_score(ytest, model_xgb.predict(xtest), average='macro'))
print('\n ** metrics.classification_report ** \n')
print(metrics.classification_report(ytest, model_xgb.predict(xtest)))

"""#Save and load machine learning models

Riferimento : https://practicaldatascience.co.uk/machine-learning/how-to-save-and-load-machine-learning-models-using
-pickle """

import pickle

pickle.dump(model_xgb, open('model_xgb.pkl', 'wb'))

print("""Esempio di reload del modello salvato""")

pickled_model = pickle.load(open('model_xgb.pkl', 'rb'))
pickled_model.predict(xtest)

print("""# Esempio previsione su una riga dei dati di test""")

# get row from NumPy array
r = xtest[4:5, :]
print(r)
pickled_model.predict(r)

print("""Esempio di previsione "leave" su dati in input""")

Education = 1  # The highest level of formal education obtained by the employee
JoiningYear = 2014  # Year of joining the company
City = 3  # Job Location
PaymentTier = 2  # [1=3] -> 3 means better payment
Age = 37  # Age of the employee
Gender = 1  # Gender of the employee
EverBenched = 0  # Ever kept out of project for more than one month
ExperienceInCurrentDomain = 5  # Experience in current field

valoriIngresso = np.array(
    [Education, JoiningYear, City, PaymentTier, Age, Gender, EverBenched, ExperienceInCurrentDomain], ndmin=2)
print(valoriIngresso)
previsione = pickled_model.predict(valoriIngresso)
# LeaveOrNot = Whether the employee leaves the company in next 2 years
if previsione[0] == 1:
    print("Leave")
else:
    print("NotLeave")

print("""Esempio di previsione "not leave" su dati in input""")

Education = 1  # The highest level of formal education obtained by the employee
JoiningYear = 2017  # Year of joining the company
City = 2  # Job Location
PaymentTier = 2  # [1=3] -> 3 means better payment
Age = 26  # Age of the employee
Gender = 0  # Gender of the employee
EverBenched = 0  # Ever kept out of project for more than one month
ExperienceInCurrentDomain = 4  # Experience in current field

valoriIngresso = np.array(
    [Education, JoiningYear, City, PaymentTier, Age, Gender, EverBenched, ExperienceInCurrentDomain], ndmin=2)
print(valoriIngresso)
previsione = pickled_model.predict(valoriIngresso)
# LeaveOrNot = Whether the employee leaves the company in next 2 years
if previsione[0] == 1:
    print("Leave")
else:
    print("NotLeave")

print("\n*** FINE   ELABORAZIONE ***")
stampa_ora()
